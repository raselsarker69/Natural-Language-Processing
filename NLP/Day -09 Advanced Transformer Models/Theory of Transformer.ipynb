{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d973ac-edc9-4bb2-be2b-10e9dfe154fb",
   "metadata": {},
   "source": [
    "## ЁЯМЯ What is a transformer?\n",
    "\n",
    "- ЁЯФ╣ржЯрзНрж░рж╛ржирзНрж╕ржлрж░ржорж╛рж░ (Transformer) ржоржбрзЗрж▓ рж╣рж▓рзЛ Deep Learning-ржПрж░ ржПржХржЯрж┐ рж╕рж░рзНржмрж╛ржзрж┐ржХ ржХрж╛рж░рзНржпржХрж░ ржУ рж╢ржХрзНрждрж┐рж╢рж╛рж▓рзА and ржПржХржЯрж┐ ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░, ржпрж╛ Natural Language Processing (NLP)-ржП ржмрзНржпрж╛ржкржХржнрж╛ржмрзЗ ржмрзНржпржмрж╣рзГржд рж╣рзЯред Google 2017 рж╕рж╛рж▓рзЗ \"Attention is All You Need\" ржкрзЗржкрж╛рж░рзЗ ржкрзНрж░ржержо ржЯрзНрж░рж╛ржирзНрж╕ржлрж░ржорж╛рж░ ржоржбрзЗрж▓ ржЙржкрж╕рзНржерж╛ржкржи ржХрж░рзЗредЁЯУМ\n",
    "\n",
    "\n",
    "- тЬЕ ржкрзНрж░ржзрж╛ржи ржмрзИрж╢рж┐рж╖рзНржЯрзНржп:\n",
    "- тЬФя╕П Self-Attention Mechanism тАУ ржжрзАрж░рзНржШржжрзВрж░ рж╕ржорзНржкрж░рзНржХ ржмрж┐рж╢рзНрж▓рзЗрж╖ржгрзЗ ржХрж╛рж░рзНржпржХрж░ред\n",
    "- тЬФя╕П Parallel Processing тАУ ржЖржЧрзЗрж░ RNN/LSTM-ржПрж░ ржЪрзЗрзЯрзЗ ржжрзНрж░рзБрждред\n",
    "- тЬФя╕П Highly Scalable тАУ GPT, BERT, T5 ржЗрждрзНржпрж╛ржжрж┐ ржоржбрзЗрж▓рзЗ ржмрзНржпржмрж╣рзГржд рж╣рзЯред\n",
    "\n",
    "---\n",
    "\n",
    "## ЁЯФ╣ЁЯТб Step 1: NLP-рждрзЗ ржЯрзНрж░рж╛ржирзНрж╕ржлрж░ржорж╛рж░ ржХрзЗржи ржкрзНрж░рзЯрзЛржЬржи?\n",
    "ЁЯТб ржкрзБрж░рзЛржирзЛ ржкржжрзНржзрждрж┐ржЧрзБрж▓рзЛрж░ рж╕рзАржорж╛ржмржжрзНржзрждрж╛ ржЯрзНрж░рж╛ржирзНрж╕ржлрж░ржорж╛рж░ ржоржбрзЗрж▓ ржЖрж╕рж╛рж░ ржЖржЧрзЗ, NLP ржЯрж╛рж╕рзНржХ-ржП ржмрзЗрж╢ ржХрж┐ржЫрзБ рж╕ржорж╕рзНржпрж╛ ржЫрж┐рж▓:\n",
    "#### 1. RNN (Recurrent Neural Networks):\n",
    "- ржХрзНрж░ржорж╛ржирзНржмрзЯрзЗ рждржерзНржп ржкрзНрж░рж╕рзЗрж╕ ржХрж░рж╛рзЯ Parallel Processing рж╕ржорзНржнржм ржирзЯред\n",
    "- рж▓ржорзНржмрж╛ ржЯрзЗржХрзНрж╕ржЯ рж╣рж▓рзЗ Long-Term Dependency рж╕ржорж╕рзНржпрж╛ рж╣рзЯред\n",
    "#### 2. LSTM (Long Short-Term Memory):\n",
    "- рж▓ржорзНржмрж╛ ржмрж╛ржХрзНржпрзЗ Gradient Vanishing Problem ржжрзЗржЦрж╛ ржжрзЗрзЯред\n",
    "- ржмрзЬ ржбрзЗржЯрж╛ ржкрзНрж░рж╕рзЗрж╕рж┐ржВ ржзрзАрж░ржЧрждрж┐ рж╕ржорзНржкржирзНржиред\n",
    "\n",
    "#### ЁЯФ╕ рзз. RNN (Recurrent Neural Network) ржУ LSTM-ржПрж░ рж╕рзАржорж╛ржмржжрзНржзрждрж╛\n",
    "- ЁЯФ┤ ржзрзАрж░ржЧрждрж┐рж░ ржкрзНрж░рж╕рзЗрж╕рж┐ржВ тАУ RNN ржПржХржмрж╛рж░рзЗ ржПржХржЯрж┐ рж╢ржмрзНржж ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ ржХрж░рзЗ, ржлрж▓рзЗ ржкрзНрж░рж╢рж┐ржХрзНрж╖ржг ржзрзАрж░ рж╣рзЯред\n",
    "- ЁЯФ┤ Long-Term Dependency рж╕ржорж╕рзНржпрж╛ тАУ ржмрзЬ ржмрж╛ржХрзНржпрзЗрж░ ржжрзАрж░рзНржШ ржжрзВрж░рждрзНржмрзЗрж░ рж╢ржмрзНржжржЧрзБрж▓рзЛрж░ ржоржзрзНржпрзЗ рж╕ржВржпрзЛржЧ ржжрзБрж░рзНржмрж▓ рж╣рзЯрзЗ ржпрж╛рзЯред\n",
    "- ЁЯФ┤ Parallelization ржХрж░рж╛ рж╕ржорзНржнржм ржирзЯ тАУ RNN рж╕рж┐рж░рж┐рзЯрж╛рж▓ ржкрзНрж░рж╕рзЗрж╕рж┐ржВ ржХрж░рзЗ, рждрж╛ржЗ GPU-рждрзЗ ржХрж╛ржЬ ржХржо ржХрж╛рж░рзНржпржХрж░ред\n",
    "\n",
    "тЬЕ ржЯрзНрж░рж╛ржирзНрж╕ржлрж░ржорж╛рж░ ржоржбрзЗрж▓ ржПржЗ рж╕ржорж╕рзНржпрж╛ржЧрзБрж▓рзЛ ржХрж╛ржЯрж┐рзЯрзЗ рждрзБрж▓рждрзЗ Self-Attention ржПржмржВ Parallel Processing ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗред\n",
    "тЬЕ рж╕ржорж╛ржзрж╛ржи: ржЯрзНрж░рж╛ржирзНрж╕ржлрж░ржорж╛рж░ ржоржбрзЗрж▓ ржЖрж╕рзЗ Self-Attention Mechanism ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ, ржпрж╛ ржПржХрж╕ржЩрзНржЧрзЗ рж╕ржм рж╢ржмрзНржжрзЗрж░ ржоржзрзНржпрзЗ рж╕ржВржпрзЛржЧ рждрзИрж░рж┐ ржХрж░рждрзЗ ржкрж╛рж░рзЗред\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd75d30-d2c2-4277-8b25-4e75bb8f71c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
