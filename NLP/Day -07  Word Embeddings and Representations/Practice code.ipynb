{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e4867c-daab-4084-b352-445af11b3c53",
   "metadata": {},
   "source": [
    "## Word Embeddings using BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba84a85-b3e5-426f-977c-edf6ab9d8343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab820c49-8ad4-4cf7-9c42-9ef7dd93902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall torch torchvision -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb816571-aeb7-40a9-8c34-6f9abd710212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcfd3ad4-aa5b-4322-bda9-5c28e5c33edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dad2814b-bfb9-4cf4-bb3b-d868932b7e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f852805-281e-40b1-a743-c768eccdd8b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertModel, BertTokenizer\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Pretrained ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ì ‡¶ü‡ßã‡¶ï‡ßá‡¶®‡¶æ‡¶á‡¶ú‡¶æ‡¶∞ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-multilingual-cased\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶∏‡¶π ‡¶Ö‡¶®‡ßá‡¶ï ‡¶≠‡¶æ‡¶∑‡¶æ ‡¶∏‡¶Æ‡¶∞‡ßç‡¶•‡¶® ‡¶ï‡¶∞‡ßá\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Pretrained ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ì ‡¶ü‡ßã‡¶ï‡ßá‡¶®‡¶æ‡¶á‡¶ú‡¶æ‡¶∞ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ\n",
    "model_name = \"bert-base-multilingual-cased\"  # ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶∏‡¶π ‡¶Ö‡¶®‡ßá‡¶ï ‡¶≠‡¶æ‡¶∑‡¶æ ‡¶∏‡¶Æ‡¶∞‡ßç‡¶•‡¶® ‡¶ï‡¶∞‡ßá\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£ ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü\n",
    "text = \"‡¶Ü‡¶Æ‡¶ø ‡¶´‡ßÅ‡¶ü‡¶¨‡¶≤ ‡¶≠‡¶æ‡¶≤‡ßã‡¶¨‡¶æ‡¶∏‡¶ø‡•§\"\n",
    "\n",
    "# ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü‡¶ï‡ßá ‡¶ü‡ßã‡¶ï‡ßá‡¶®‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# ‡¶Æ‡¶°‡ßá‡¶≤‡ßá ‡¶™‡¶æ‡¶†‡¶æ‡¶®‡ßã ‡¶è‡¶¨‡¶Ç ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶®‡ßá‡ßü‡¶æ\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# ‡¶≤‡¶æ‡¶∏‡ßç‡¶ü ‡¶π‡¶ø‡¶°‡ßá‡¶® ‡¶∏‡ßç‡¶ü‡ßá‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶ì‡ßü‡¶æ‡¶∞‡ßç‡¶° ‡¶è‡¶Æ‡ßç‡¶¨‡ßá‡¶°‡¶ø‡¶Ç ‡¶®‡ßá‡ßü‡¶æ\n",
    "word_embeddings = outputs.last_hidden_state\n",
    "\n",
    "# ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã\n",
    "print(\"Word Embeddings Shape:\", word_embeddings.shape)  # (batch_size, sequence_length, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d000d7-5cb0-41b8-b504-b1dc24ee49bf",
   "metadata": {},
   "source": [
    "## Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5c689d0-e1ac-4e8b-b090-cf1f6eb63ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall scipy gensim -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d5f91c-ee6a-44d3-8993-3a6a3db33005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade scipy gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b91ca62-d422-4c0c-846c-1be0c274d4fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\__init__.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\corpora\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\corpora\\indexedcorpus.py:14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[0;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\interfaces.py:19\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\matutils.py:1034\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 \u001b[38;5;241m&\u001b[39m set2)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1033\u001b[0m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[1;32m-> 1034\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogsumexp\u001b[39m(x):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\_matutils.pyx:1\u001b[0m, in \u001b[0;36minit gensim._matutils\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# \n",
    "sentences = [\n",
    "    \"‡¶Ü‡¶Æ‡¶ø ‡¶´‡ßÅ‡¶ü‡¶¨‡¶≤ ‡¶ñ‡ßá‡¶≤‡¶§‡ßá ‡¶≠‡¶æ‡¶≤‡ßã‡¶¨‡¶æ‡¶∏‡¶ø\",\n",
    "    \"‡¶∏‡ßá ‡¶¨‡¶æ‡¶∏‡ßç‡¶ï‡ßá‡¶ü‡¶¨‡¶≤ ‡¶ñ‡ßá‡¶≤‡¶§‡ßá ‡¶™‡¶õ‡¶®‡ßç‡¶¶ ‡¶ï‡¶∞‡ßá\",\n",
    "    \"‡¶´‡ßÅ‡¶ü‡¶¨‡¶≤ ‡¶ì ‡¶¨‡¶æ‡¶∏‡ßç‡¶ï‡ßá‡¶ü‡¶¨‡¶≤ ‡¶ú‡¶®‡¶™‡ßç‡¶∞‡¶ø‡¶Ø‡¶º ‡¶ñ‡ßá‡¶≤‡¶æ\",\n",
    "    \"‡¶∏‡ßá ‡¶è‡¶ï‡¶ú‡¶® ‡¶Ö‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶´‡ßÅ‡¶ü‡¶¨‡¶≤ ‡¶ñ‡ßá‡¶≤‡ßã‡¶Ø‡¶º‡¶æ‡¶°‡¶º\"\n",
    "]\n",
    "\n",
    "# **‡¶ü‡ßã‡¶ï‡ßá‡¶®‡¶æ‡¶á‡¶ú‡ßá‡¶∂‡¶® (‡¶∂‡¶¨‡ßç‡¶¶ ‡¶¨‡¶ø‡¶≠‡¶ï‡ßç‡¶§‡¶ø)**\n",
    "tokenized_sentences = [word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "# üéØ **Word2Vec ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶® ‡¶ï‡¶∞‡¶æ**\n",
    "model = Word2Vec(sentences=tokenized_sentences, vector_size=10, window=2, min_count=1, workers=4)\n",
    "\n",
    "# **‡¶è‡¶ï‡¶ü‡¶ø ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶∂‡¶¨‡ßç‡¶¶‡ßá‡¶∞ ‡¶≠‡ßá‡¶ï‡ßç‡¶ü‡¶∞ ‡¶¶‡ßá‡¶ñ‡¶æ (Error Handling ‡¶∏‡¶π)**\n",
    "word = \"‡¶´‡ßÅ‡¶ü‡¶¨‡¶≤\"\n",
    "if word in model.wv:\n",
    "    print(f\"\\n'{word}' ‡¶∂‡¶¨‡ßç‡¶¶‡ßá‡¶∞ ‡¶≠‡ßá‡¶ï‡ßç‡¶ü‡¶∞:\\n\", model.wv[word])\n",
    "else:\n",
    "    print(f\"\\n'{word}' ‡¶∂‡¶¨‡ßç‡¶¶‡¶ü‡¶ø ‡¶Æ‡¶°‡ßá‡¶≤‡ßá ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü‡¶®‡¶ø‡•§\")\n",
    "\n",
    "# **‡¶∏‡¶Æ‡¶æ‡¶® ‡¶ß‡¶∞‡¶£‡ßá‡¶∞ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶ñ‡ßã‡¶Å‡¶ú‡¶æ (Error Handling ‡¶∏‡¶π)**\n",
    "try:\n",
    "    print(f\"\\n'{word}' ‡¶∂‡¶¨‡ßç‡¶¶‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡¶ø‡¶§ ‡¶∂‡¶¨‡ßç‡¶¶:\\n\", model.wv.most_similar(word))\n",
    "except KeyError:\n",
    "    print(f\"\\n'{word}' ‡¶∂‡¶¨‡ßç‡¶¶‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡¶ø‡¶§ ‡¶ï‡ßã‡¶®‡ßã ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶Æ‡¶°‡ßá‡¶≤‡ßá ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü‡¶®‡¶ø‡•§\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bfd5df-6b90-4bf7-bf00-62c725cd70a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
